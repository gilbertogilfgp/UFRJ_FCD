{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "logical-friday",
   "metadata": {},
   "source": [
    "![PPGI_UFRJ](imagens/ppgi-ufrj.png)\n",
    "# Fundamentos de Ciência de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-brush",
   "metadata": {},
   "source": [
    "---\n",
    "# PPGI/UFRJ 2020.3, 2022.2\n",
    "## Prof Sergio Serra e Jorge Zavaleta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-decline",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Provenance em Python\n",
    "## Adding Provenance to an Example\n",
    "\n",
    "## Provenance: An Introduction to PROV\n",
    "### Luc Moreau and Paul Groth\n",
    "### http://www.provbook.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-chambers",
   "metadata": {},
   "source": [
    "## 1- Installation of PROV Library\n",
    "\n",
    "To install the prov library using pip with support for graphical exports:\n",
    "--> Use Anaconda prompt command window and type \n",
    "\n",
    "```pip install prov```   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-optics",
   "metadata": {},
   "source": [
    "Step-by-Step to add PROV on Python Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import ProvDocument to you Python Code\n",
    "from prov.model import ProvDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new provenance document\n",
    "d1 = ProvDocument()  # d1 is now an empty provenance document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring namespaces for various prefixes used in the example\n",
    "d1.add_namespace('now', 'http://www.provbook.org/nownews/')\n",
    "d1.add_namespace('nowpeople', 'http://www.provbook.org/nownews/people/')\n",
    "d1.add_namespace('bk', 'http://www.provbook.org/ns/#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding an Entity: now:employment-article-v1.html\n",
    "e1 = d1.entity('now:employment-article-v1.html')\n",
    "# Adding an Agent: nowpeople:Bob\n",
    "d1.agent('nowpeople:Zavaleta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributing the article to the agent\n",
    "d1.wasAttributedTo(e1, 'nowpeople:Zavaleta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-static",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing what we have so far (serialized in PROV-N)\n",
    "print(d1.get_provn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding more namespace declarations\n",
    "d1.add_namespace('govftp', 'ftp://ftp.bls.gov/pub/special.requests/oes/')\n",
    "d1.add_namespace('void', 'http://vocab.deri.ie/void#')\n",
    "\n",
    "# Connecting entitites\n",
    "# 'now:employment-article-v1.html' was derived from at dataset at govftp\n",
    "d1.entity('govftp:oesm11st.zip', {'prov:label': 'employment-stats-2011', 'prov:type': 'void:Dataset'})\n",
    "d1.wasDerivedFrom('now:employment-article-v1.html', 'govftp:oesm11st.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing what we have so far\n",
    "print(d1.get_provn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-floating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding an activity\n",
    "d1.add_namespace('is', 'http://www.provbook.org/nownews/is/#')\n",
    "d1.activity('is:writeArticle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new relations- Usage and Generation\n",
    "d1.used('is:writeArticle', 'govftp:oesm11st.zip')\n",
    "d1.wasGeneratedBy('now:employment-article-v1.html', 'is:writeArticle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-cologne",
   "metadata": {},
   "source": [
    "# 2 - Graphics export (PNG and PDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-there",
   "metadata": {},
   "source": [
    "## Installation of visualization libraries\n",
    "--> Use Anaconda prompt command window and type \n",
    "\n",
    "```conda install graphviz```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install graphviz - CMD\n",
    "# visualize the graph\n",
    "\n",
    "# Generating the provenance graph\n",
    "from prov.dot import prov_to_dot\n",
    "dot = prov_to_dot(d1)\n",
    "dot.write_png('imagens/article-prov.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Vizualization the provenance graph in the Jupyter notebook\n",
    "from IPython.display import Image\n",
    "Image('imagens/article-prov.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-minimum",
   "metadata": {},
   "source": [
    "**Installation of PDF libraries**\n",
    "--> **Use Anaconda prompt command window and type**\n",
    "\n",
    "### conda install -c conda-forge pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-award",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge pydotplus\n",
    "# Or save to a PDF\n",
    "dot.write_pdf('pdf/article-prov.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-alaska",
   "metadata": {},
   "source": [
    "# 3- Serializaning and Exporting the Data Provenance as PROV-JSON \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializaning Provenance as JSON and showing in the Jupyter notebook\n",
    "print(d1.serialize(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializaning Provenance as JSON and saving as a JSON file\n",
    "d1.serialize('data/article-prov.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-sleeve",
   "metadata": {},
   "source": [
    "# 4- XML and Turtle (RDF) Support\n",
    "## Serializaning and Exporting the Data Provenance as XML and Turtle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializaning Provenance as XML and saving as a XML file\n",
    "d1.serialize('data/article-prov.xml', format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-longitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializaning Provenance as Turtle and saving as a TTL file\n",
    "d1.serialize('data/article-prov.ttl', format='rdf', rdf_format='ttl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-tourism",
   "metadata": {},
   "source": [
    "# 5 - (Optional) Store and retrieve provenance documents from ProvStore\n",
    "\n",
    "## The next two steps are optional\n",
    "\n",
    "#### Check if the  ProvStore is up and running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure ProvStore API Wrapper with your API Key\n",
    "from provstore.api import Api\n",
    "# see your API key at https://openprovenance.org/store/account/developer/\n",
    "api = Api(base_url='https://openprovenance.org/store/api/v0', username='<your-username>', api_key='<your-API-key>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the document to ProvStore\n",
    "provstore_document = api.document.create(d1, name='article-prov', public=True)\n",
    "\n",
    "# Generate a nice link to the document on ProvStore so you don't have to find it manually \n",
    "from IPython.display import HTML\n",
    "document_uri = provstore_document.url\n",
    "HTML('<a href=\"%s\" target=\"_blank\">Open your new provenance document on ProvStore</a>' % document_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-seven",
   "metadata": {},
   "source": [
    "# 6- Vamos retomar o exemplo de experimento reprodutível (R4) \n",
    "##  Vamos instrumentar aquele código python com PROV Library\n",
    "\n",
    "### O código R4 também foi parametrizado - Leia e Execute com atenção... com atenção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random walk (R4) with PROV\n",
    "# Copyright (c) 2017 N.P. Rougier and F.C.Y. Benureau\n",
    "# Adapted by Serra\n",
    "# Release under the Windows 10\n",
    "# Pyhton 3.8 - Jupyter notebook\n",
    "# Tested with 64 bit (AMD64) \n",
    "\n",
    "import sys, subprocess, datetime, random\n",
    "from prov.model import ProvDocument                                                 #PROV Library\n",
    "\n",
    "# Retrospective Provenance variables\n",
    "agent    = input(\"Enter the name of the AGENT WHO is running the program: \")        #PROV-Agent\n",
    "entity   = input(\"Enter the name of the ENTITY dataset: \")                          #PROV-Entity\n",
    "activity = input(\"Enter the name of the ACTIVITY: \")                                #PROV-Activity\n",
    "graph = entity                                                                      #PROV-Graph\n",
    "\n",
    "def compute_walk(count, x0=0, step=1, seed=0):\n",
    "    \"\"\"Random walk\n",
    "       count: number of steps\n",
    "       x0   : initial position (default 0)\n",
    "       step : step size (default 1)\n",
    "       seed : seed for the initialization of the\n",
    "\t     random generator (default 0)\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    x = x0\n",
    "    walk = []\n",
    "    for i in range(count):\n",
    "        if random.uniform(-1, +1) > 0:\n",
    "            x += 1\n",
    "        else:\n",
    "            x -= 1\n",
    "        walk.append(x)\n",
    "    return walk\n",
    "\n",
    "def compute_results(count, x0=0, step=1, seed=0):\n",
    "    \"\"\"Compute a walk and return it with context\"\"\"\n",
    "\n",
    "    # Get hash if any\n",
    "    hash_cmd = (\"notepad\", \"rev-parse\", \"HEAD\")\n",
    "    revision = subprocess.check_output(hash_cmd)\n",
    "\n",
    "    # Compute results and some Retrospective Provenance inside the file\n",
    "    walk = compute_walk(count=count, x0=x0,\n",
    "                        step=step, seed=seed)\n",
    "    return {\n",
    "        \"data\"      : walk,\n",
    "        \"filename\"  : entity+\".txt\",\n",
    "        \"parameters\": {\"count\": count, \"x0\": x0,\n",
    "                       \"step\": step, \"seed\": seed},\n",
    "        \"timestamp\" : str(datetime.datetime.utcnow()),\n",
    "        \"revision\"  : revision,\n",
    "        \"system\"    : sys.version        \n",
    "                   }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Unit test checking reproducibility\n",
    "    # (will fail with Python<=3.2)\n",
    "    assert (compute_walk(10, 0, 1, 42) ==\n",
    "\t        [1,0,-1,-2,-1,0,1,0,-1,-2])\n",
    "\n",
    "    # Simulation parameters\n",
    "    count, x0, seed = 10, 0, 1\n",
    "    results = compute_results(count, x0=x0, seed=seed)\n",
    "\n",
    "    # Save & display results of computing\n",
    "    with open(entity+\".txt\", \"w\") as fd: \n",
    "        fd.write(str(results))\n",
    "    print(results[\"data\"])\n",
    "\n",
    "### BEGIN - Registering Retrospective Provenance -             #PROV-MODEL\n",
    "### Experiment Randon Walk Experiment  \n",
    "\n",
    "# Creating an empty provenance document\n",
    "d1 = ProvDocument()                                                 \n",
    "\n",
    "# Declaring namespaces for various prefixes used in the excution of Randon Walk Experiment\n",
    "d1.add_namespace('ufrj', 'http://www.ufrj.br/ppgi/')\n",
    "d1.add_namespace('foaf', 'http://xmlns.com/foaf/0.1/')\n",
    "d1.add_namespace('greco', 'http://www.ufrj.br/ppgi/greco/#')\n",
    "\n",
    "# Adding an entity\n",
    "entity = \"ufrj:\"+ entity\n",
    "e1 = d1.entity(entity)\n",
    "\n",
    "# Adding an Agent \n",
    "agent = \"foaf:\"+ agent\n",
    "d1.agent(agent)\n",
    "\n",
    "# Attributing the execution of the experiment to the PROV-Agent\n",
    "d1.wasAttributedTo(e1, agent)\n",
    "\n",
    "# Adding an activity\n",
    "activity = \"greco:\"+ activity\n",
    "d1.activity(activity)\n",
    "\n",
    "# Generation\n",
    "d1.wasGeneratedBy( entity, activity)\n",
    "\n",
    "# Adding a role to the PROV-Agent and timestamp to dataset\n",
    "d1.agent(agent, {'prov:hadRole': 'Executor', 'foaf:mbox': 'sergioserra@gmail.com', 'prov:attributedAtTime': str(datetime.datetime.utcnow())})\n",
    "d1.entity(entity, {'prov:generatedAtTime': str(datetime.datetime.utcnow())})\n",
    "\n",
    "### END - Registering Retrospective Provenance \n",
    "\n",
    "### Optional outputs ####\n",
    "\n",
    "#Generating the outup - a  Provenance Graph\n",
    "from prov.dot import prov_to_dot\n",
    "dot = prov_to_dot(d1)\n",
    "graph = graph +\".png\"\n",
    "dot.write_png(graph)\n",
    "\n",
    "#Generating the Serialization - Output XML\n",
    "d1.serialize(entity + \".xml\", format='xml') \n",
    "\n",
    "#Generating the Serialization - Output Turtle\n",
    "d1.serialize(entity + \".ttl\", format='rdf', rdf_format='ttl') \n",
    "\n",
    "#Generating the outup of Provenance document\n",
    "#print ('')\n",
    "#print ('simple provenance doc')\n",
    "#print(d1.get_provn())\n",
    "#print ('')\n",
    "\n",
    "#Generating the Serialization - Output JASON\n",
    "#print ('')\n",
    "#print ('simple provenance JSON')\n",
    "#print(d1.serialize(indent=2))\n",
    "#print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-floating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Vizualization the provenance graph in the Jupyter notebook\n",
    "from IPython.display import Image\n",
    "Image(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-sierra",
   "metadata": {},
   "source": [
    "---\n",
    "#### &copy; Copyright 2021, Sergio Serra & Jorge Zavaleta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
